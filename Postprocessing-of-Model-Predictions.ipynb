{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b869fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "import datetime\n",
    "import h5py\n",
    "import glob\n",
    "import os\n",
    "import scipy.signal\n",
    "import cv2\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40dec81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 23:01:10.102492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30178 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0004:04:00.0, compute capability: 7.0\n",
      "2023-09-04 23:01:10.103805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 26281 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0035:03:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#load raw 30 freq model \n",
    "json_file = open('/scratch/gpfs/kx2561/ML/rawSpecModels/rawSpec_30f/newest_MLPmodel_30freq.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights('/scratch/gpfs/kx2561/ML/rawSpecModels/rawSpec_30f/newest_MLPmodel_30freq.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727dfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing parameters-- vary for different models\n",
    "lookBefore = 5   # check if a 1 exists in (lookBefore) places before and after\n",
    "howLong = 250 # length of small chunks of 1s to remove\n",
    "threshold = 0.378   # threshold in which the raw prediction is interpreted as a \"1\"/\"Mode\"\n",
    "breakTime = 0.015  # break time between chunks of 1s at the end of postprocessing (link together the full temporal presence of the mode)\n",
    "\n",
    "# get all times (for one spectrogram). Can also just load shot with Sxx, Sxx_enhanced, f, t = loadShot(193727, 3)\n",
    "df = pd.read_csv('/scratch/gpfs/kx2561/ML/rawSpecModels/rawSpec_30f/Times.csv')\n",
    "t = df['Times']\n",
    "\n",
    "# mode shots to look at (these channels specifically I had checked and were not in the training set)\n",
    "modeShots = [194045, 194043, 194399, 194123, 193782, 193752,193754, 193727, 193843, 193806, 193775, 193782, 194050, 194128, 194128, 194467, 194468, 193807, 193716, 193691, 193691, 193690, 194048, 194048, 194052, 194399, 194046, 194047]\n",
    "modeChns = [3, 4, 6, 4,6, 3, 4, 6, 4, 4, 5, 4,6,3, 4, 4, 3, 4, 4, 3, 5, 3, 3, 4, 5, 4, 4, 4]\n",
    "\n",
    "# modeless shots to look at\n",
    "modelessShots = [193806, 194370, 194009, 193691, 194371, 193731, 194042, 193995, 194370, 194370, 194385, 194371, 194371, 194470, 194009, 194051, 193685, 193807, 194279, 194468, 193695, 193695, 194081, 194128, 193782, 193843, 193752, 193754, 194049]\n",
    "modelessChns = [7, 6, 8, 6, 6, 5, 7, 6, 6, 3, 3, 6, 4, 7, 5, 7, 5, 6, 5, 5, 6, 5, 7, 6, 7, 3, 7, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37505ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### spectrogram enhancement ###############\n",
    "def specgr (sig_in,spec_params,thr=0.9, gaussblr_win=(31,3)):\n",
    "    f, t, Sxx = scipy.signal.spectrogram(sig_in, nperseg=spec_params['nperseg'], noverlap=spec_params['noverlap'],fs=spec_params['fs'], window=spec_params['window'],scaling=spec_params['scaling'], detrend=spec_params['detrend'])\n",
    "    Sxx = np.log(Sxx + spec_params['eps']) #offset by epsilon to prevent log(0)\n",
    "    Sxx=(Sxx-np.min(Sxx))/(np.max(Sxx)-np.min(Sxx)) #z score scaling\n",
    "    Sxx = Sxx[:-1,:];f=f[:-1] \n",
    "    \n",
    "    Sxx_enhanced = quantfilt(Sxx,thr) \n",
    "    Sxx_enhanced = gaussblr(Sxx_enhanced,gaussblr_win)\n",
    "    Sxx_enhanced = meansub(Sxx_enhanced)    \n",
    "    Sxx_enhanced = morph(Sxx_enhanced)\n",
    "    Sxx_enhanced = meansub(Sxx_enhanced)    \n",
    "    return Sxx,Sxx_enhanced,f/1000,t\n",
    "\n",
    "\n",
    "def norm(data):\n",
    "    mn = data.mean()\n",
    "    std = data.std()\n",
    "    return((data-mn)/std)\n",
    "\n",
    "def rescale(data):\n",
    "    return (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "def quantfilt(src,thr=0.9):\n",
    "    filt = np.quantile(src,thr,axis=0)\n",
    "    out = np.where(src<filt,0,src)\n",
    "    return out\n",
    "\n",
    "# gaussian filtering (just get middle part, filter out highs and lows)\n",
    "def gaussblr(src,filt=(31, 3)):\n",
    "    src = (rescale(src)*255).astype('uint8')\n",
    "    out = cv2.GaussianBlur(src,filt,0)\n",
    "    return rescale(out)\n",
    "\n",
    "# mean filtering\n",
    "def meansub(src):\n",
    "    mn = np.mean(src,axis=1)[:,np.newaxis]\n",
    "    out = np.absolute(src - mn)\n",
    "    return rescale(out)\n",
    "\n",
    "# morphological filtering\n",
    "def morph(src):\n",
    "    src = (rescale(src)*255).astype('uint8')\n",
    "    se1 = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "    se2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3,1))\n",
    "    mask = cv2.morphologyEx(src, cv2.MORPH_CLOSE, se1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)\n",
    "    return rescale(mask)\n",
    "\n",
    "spec_params={\n",
    "    'nperseg': 800, # default 1024\n",
    "    'noverlap': 550, # default: nperseg / 4\n",
    "    'fs': 500000, # raw signal sample rate is 4MHz\n",
    "    'window': 'hamm',\n",
    "    'scaling': 'density', # {'density', 'spectrum'}\n",
    "    'detrend': 'linear', # {'linear', 'constant', False}\n",
    "    'eps': 1e-11} \n",
    "\n",
    "def loadShot(shotn,ece_chn):\n",
    "    # data_spec = pickle.load(open(os.path.join('/projects/EKOLEMEN/negd_ece/negd_spec/','%d.pkl' % (shotn)),'rb'))\n",
    "    #rb is read binary \n",
    "    data_raw = pickle.load(open(os.path.join('/projects/EKOLEMEN/negd_ece/negd_raw/','%d.pkl' % (shotn)),'rb')) \n",
    "    return specgr (data_raw[f'ECEVS{ece_chn:02d}'],spec_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd694766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on shots (look at performance)\n",
    "def makePrediction(loaded_model, spec):\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(spec.shape[-1]):\n",
    "        make_pred = loaded_model.predict(spec[:30, i].reshape(1, 30))  # first 30 frequencies of raw spec\n",
    "        predictions.append(make_pred[0][0])\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30e1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### model postprocessing algorithm begins here ###########\n",
    "# Step 1: turn raw predictions into series of 0s and 1s (1 if past a certain threshold)\n",
    "def processPredictions(a, threshold):\n",
    "    newCol = []\n",
    "\n",
    "    #parse through raw predictions\n",
    "    for i in range(len(a)):\n",
    "        if a[i] >= threshold:\n",
    "            newCol.append(1)\n",
    "        else:\n",
    "            newCol.append(0)\n",
    "        \n",
    "    return newCol   # predictions in format of 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c642117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: interpolation (look at previous and later predictions to turn 0s to 1s)\n",
    "def filtering(column, lookBefore):\n",
    "    newCol = column.copy()   # column of model predictions (0s or 1s)\n",
    "    \n",
    "    # move backwards through the raw predictions to check \n",
    "    for i in range(len(newCol)-1, -1, -1):\n",
    "        difference = i - lookBefore    # lookBefore = how many previous values to look at\n",
    "        if difference < 0:\n",
    "            nStart = 0  # nstart = the first previous index to look at  (Ex. for i = 5 and lookBefore = 5, I'd look at 0, 1, 2, 3, and 4)\n",
    "        else:\n",
    "            nStart = difference  \n",
    "    \n",
    "        upperCheck = i + lookBefore + 1  # the last following index to look at (Ex. for i = 5 and lookBefore = 5, looking at 6, 7, 8, 9, 10)\n",
    "        if upperCheck > len(column):\n",
    "            upperCheck = len(column)\n",
    "                \n",
    "        # interpolation with upper and lower indices to check\n",
    "        if newCol[i] == 0:\n",
    "            seenBefore = False\n",
    "            seenAfter = False\n",
    "            for index in range(nStart, i):\n",
    "                if newCol[index] == 1:\n",
    "                    seenBefore = True   # if there is at least one \"1\" in the nPast indices before the \"0\"\n",
    "            \n",
    "            for j in range(i, upperCheck):\n",
    "                if newCol[j] == 1:\n",
    "                    seenAfter = True\n",
    "            \n",
    "            if seenBefore and seenAfter:  \n",
    "                newCol[i] = 1\n",
    "                \n",
    "        # zeroes an isolated 1 if it's surrounded on both sides by zeroes (ex. 0 1 0 => 0 0 0)\n",
    "        if newCol[i] == 1:\n",
    "            if i == 0:\n",
    "                if column[i+1] == 0:\n",
    "                    newCol[i] = 0\n",
    "            elif i == len(newCol)-1:\n",
    "                if column[i-1] == 0:\n",
    "                    newCol[i] = 0\n",
    "            else:\n",
    "                if newCol[i-1] == 0 and newCol[i+1] == 0:\n",
    "                    newCol[i] = 0\n",
    "                    \n",
    "    return newCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ccc4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: filter out small isolated chunks of 1s (limit randomness of predictions)\n",
    "# threshold = the upper limit on the length of the isolated chunk (2 = 0.001 s, 3 = 0.0015 s)\n",
    "def filteringOnes(arr, threshold):\n",
    "    ones = []\n",
    "    removeIndices = []  # which indices to turn from zeros to ones\n",
    "    processedArr = arr.copy()\n",
    "    \n",
    "    for index in range(len(arr)):\n",
    "        if arr[index] == 1:\n",
    "            ones.append(index)\n",
    "            \n",
    "    indices = filtering2(ones, 1.00005)  # get locations of ones (ie if 1 at 3, and 1 at 4, it returns (3, 4)\n",
    "    #print(indices)\n",
    "    \n",
    "    for i in indices:\n",
    "        if (i[-1] - i[0]) <= threshold-1: # ex. threshold of 2 indicates a small burst of 0.001 s\n",
    "            for val in range(i[0], i[-1]+1):\n",
    "                removeIndices.append(val)   # add \n",
    "                \n",
    "    for r in removeIndices:\n",
    "        processedArr[r] = 0\n",
    "    return processedArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6132b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: get start and end of mode (temporal presence)\n",
    "def filtering2(col, breakTime):\n",
    "    newCol = []\n",
    "    start = 0\n",
    "    end = 0  \n",
    "    \n",
    "    column = [i for i in col if i != 0]\n",
    "    \n",
    "    for i in range(1, len(column)):\n",
    "        if column[i] != 'N/A':\n",
    "            currentStart = column[i]\n",
    "            currentEnd = column[i-1]\n",
    "            \n",
    "            if start == 0 and currentStart - currentEnd <= (breakTime + 0.00005):\n",
    "                start = column[i-1]\n",
    "                end = column[i]\n",
    "            \n",
    "            elif currentStart - end <= (breakTime + 0.00005):   # added to account for floating point inaccuracy\n",
    "                end = column[i]\n",
    "                \n",
    "            elif (end - start) > 0:\n",
    "                newCol.append((start, end))\n",
    "                start = 0\n",
    "                end = 0\n",
    "            else:\n",
    "                start = 0\n",
    "                end = 0\n",
    "                \n",
    "        if i == len(column)-1:\n",
    "            if end-start > 0:\n",
    "                newCol.append((start, end))\n",
    "\n",
    "    return newCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fb290ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot postprocessed predictions\n",
    "# plot raw signal, spectrogram, enhanced spectrogram, and predictions v. time with rolling average line\n",
    "# upperBound = upper boundary of frequency space (ie 30 => first 30 frequencies are plotted)\n",
    "# times = predicted 1s of the model\n",
    "# mode: False if shot is modeless, True if shot has mode\n",
    "# raw predictions = array of model predictions on whole spectrogram\n",
    "def plotECE(tGood, shotn, ece_chn, upperBound, times, rawPredictions, mode):\n",
    "    data_raw = pickle.load(open(os.path.join('/projects/EKOLEMEN/negd_ece/negd_raw/','%d.pkl' % (shotn)),'rb')) \n",
    "    Sxx,Sxx_enhanced,f,t = loadShot(shotn, ece_chn)\n",
    "    Sxx[upperBound:, :] = 0\n",
    "    Sxx_enhanced[upperBound:, :] = 0\n",
    "     \n",
    "    fig = plt.figure(figsize=(10,8),dpi=100)\n",
    "    \n",
    "    grd = gridspec.GridSpec(7, 1)\n",
    "    \n",
    "   \n",
    "    if mode: \n",
    "        a = pickle.load(open(f'/scratch/gpfs/aj17/datasets/NT-dataset/dataset/mode/shot-{shotn}-ece-{chn}.pkl', 'rb'))\n",
    "        modeStart = a['Mode Start Time(s)']\n",
    "        modeEnd = a['Mode End Time(s)'] \n",
    "    else:\n",
    "        a = pickle.load(open(f'/scratch/gpfs/aj17/datasets/NT-dataset/dataset/nomode/shot-{shotn}-ece-{chn}.pkl', 'rb'))\n",
    "    \n",
    "    # raw ECE signal\n",
    "    ax = fig.add_subplot(grd[0])\n",
    "    ax.plot(data_raw['times'],data_raw[f'ECEVS{ece_chn:02d}'])\n",
    "    _=plt.title('Shot# %i - ECE# %i' % (shotn,ece_chn))\n",
    "    _=plt.xlim(data_raw['times'][0],data_raw['times'][-1])\n",
    "    _=plt.ylim([-1,10])\n",
    "    _=plt.ylabel('raw ece')\n",
    "\n",
    "    # draw raw spectrogram for first (upperBound) frequencies\n",
    "    ax = fig.add_subplot(grd[1:3])\n",
    "    ax.pcolormesh(tGood,f[:upperBound],Sxx[:upperBound, tstart:tend],shading='auto', cmap='hot')\n",
    "    \n",
    "    # draw out prediction\n",
    "    for i in range(len(times)):\n",
    "        ax.hlines(y=2, xmin=times[i][0], xmax=times[i][1], linewidth=4, color='lavenderblush')\n",
    "        \n",
    "    #draw out actual mode\n",
    "    if mode:\n",
    "        for m in range(len(modeStart)):\n",
    "            ax.hlines(y=0.5, xmin=modeStart[m], xmax=modeEnd[m], linewidth=4, color='lime')\n",
    "        \n",
    "    _=plt.xlabel(f'ECE Channel {ece_chn}')\n",
    "    _=plt.ylabel('raw spectrogram -kHz')\n",
    "    \n",
    "    \n",
    "    ax = fig.add_subplot(grd[3:5])\n",
    "    c = ax.pcolormesh(tGood,f[:upperBound],Sxx_enhanced[:upperBound, tstart:tend],shading='auto', cmap='hot')\n",
    "   # plt.xticks(np.arange(0.5, 6, 0.25))\n",
    "    \n",
    "    # draw out prediction\n",
    "    for i in range(len(times)):\n",
    "        ax.hlines(y=2, xmin=times[i][0], xmax=times[i][1], linewidth=4, color='lavenderblush')\n",
    "    \n",
    "    #draw out actual mode\n",
    "    if mode:\n",
    "        for m in range(len(modeStart)):\n",
    "            ax.hlines(y=0.5, xmin=modeStart[m], xmax=modeEnd[m], linewidth=4, color='lime')\n",
    "        \n",
    "    plt.xticks(rotation=45)\n",
    "    _=plt.xlabel('Time (s) ')\n",
    "    _=plt.ylabel('enhanced spectrogram -kHz')\n",
    "\n",
    "    # get raw predictions and plot against time; smooth fluctuations with rolling average line\n",
    "    col = pd.DataFrame(rawPredictions)\n",
    "    colAve = col.rolling(130).mean()\n",
    "    \n",
    "    ax = fig.add_subplot(grd[5:])\n",
    "    # plot raw predictions vs Mode\n",
    "    plt.plot(tGood, col, 'b')\n",
    "    plt.plot(tGood, colAve, 'r')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Raw Prediction')\n",
    "\n",
    "    # save figures into folder\n",
    "    if mode: \n",
    "        plt.savefig(f'/scratch/gpfs/kx2561/ML/rawSpecModels/newUpdate/not_training/plots/fourPlots/visualization_prediction-MODE-shot-{shotn}-chn-{chn}.jpg')\n",
    "    else:           \n",
    "        plt.savefig(f'/scratch/gpfs/kx2561/ML/rawSpecModels/newUpdate/not_training/plots/fourPlots/visualization_prediction-MODELESS-shot-{shotn}-chn-{chn}.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82592b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations of postprocessed model predictions: mode shots\n",
    "for i in tqdm(range(len(modeShots))):\n",
    "    shotn = modeShots[i]\n",
    "    chn = modeChns[i]\n",
    "    df = pd.read_csv(f'/scratch/gpfs/kx2561/ML/rawSpecModels/newUpdate/not_training/MODE_raw30f_predictions-shot-{shotn}-chn-{chn}.csv')\n",
    "\n",
    "    a = pickle.load(open(f'/scratch/gpfs/aj17/datasets/NT-dataset/dataset/mode/shot-{shotn}-ece-{chn}.pkl', 'rb'))\n",
    "    goodIndex = a['Shot Beginning t-index']\n",
    "    badIndex = a['Shot Ending t-index']\n",
    "    tGood = np.array(t[goodIndex:badIndex])  # times \n",
    "\n",
    "    rawSpec = a['raw spectrogram']\n",
    "    \n",
    "    # get raw predictions on raw spectrogram\n",
    "    col = makePrediction(loaded_model, rawSpec) # raw predictions\n",
    "    \n",
    "    # convert raw predictions to 1s and 0s\n",
    "    make_pred = processPredictions(col, threshold)  \n",
    "    \n",
    "    # interpolation and removing isolated ones\n",
    "    make_pred = filtering(make_pred, lookBefore)\n",
    "    \n",
    "    # remove tiny chunks of ones again after interpolation (anything <= 0.15 sec left from consideration)\n",
    "    # howLong * 0.0005 s is the upper limit of the chunk (anything equal to or less will be turned into 0s)\n",
    "    # 300 => 0.15 seconds\n",
    "    make_pred = filteringOnes(make_pred, howLong)\n",
    "    \n",
    "    # converting 1s and 0s to times      \n",
    "    predicted_times = tGood * np.array(make_pred)\n",
    "\n",
    "    # find continuous durations of the mode\n",
    "    durations = filtering2(predicted_times, breakTime)\n",
    "\n",
    "    # plot postprocessed prediction on spectrogram\n",
    "    plotECE(tGood, shotn, chn, 30, durations, col, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations of postprocessed model predictions: modeless shots\n",
    "for i in tqdm(range(len(modelessShots))):\n",
    "    shotn = modelessShots[i]\n",
    "    chn = modelessChns[i]\n",
    "\n",
    "    a = pickle.load(open(f'/scratch/gpfs/aj17/datasets/NT-dataset/dataset/nomode/shot-{shotn}-ece-{chn}.pkl', 'rb'))\n",
    "    goodIndex = a['Shot Beginning t-index']\n",
    "    badIndex = a['Shot Ending t-index']\n",
    "    tGood = np.array(t[goodIndex:badIndex])  # times \n",
    "    rawSpec = a['raw spectrogram']\n",
    "    \n",
    "    # get raw predictions on raw spectrogram\n",
    "    col = makePrediction(loaded_model, rawSpec) # raw predictions\n",
    "\n",
    "    # convert raw predictions to 1s and 0s\n",
    "    make_pred = processPredictions(col, threshold)\n",
    "    \n",
    "    # interpolation and removing isolated ones\n",
    "    make_pred = filtering(make_pred, lookBefore)\n",
    "    \n",
    "    # remove tiny chunks of ones again after interpolation (anything <= 0.15 sec left from consideration)\n",
    "    # howLong * 0.0005 s is the upper limit of the chunk (anything equal to or less will be turned into 0s)\n",
    "    # 300 => 0.15 seconds\n",
    "    make_pred = filteringOnes(make_pred, howLong)\n",
    "    \n",
    "    # converting 1s and 0s to times      \n",
    "    predicted_times = tGood * np.array(make_pred)\n",
    "\n",
    "    # find continuous durations of the mode\n",
    "    durations = filtering2(predicted_times, breakTime)\n",
    "    \n",
    "    # plot postprocessed prediction on spectrogram\n",
    "    plotECE(tGood, shotn, chn, 30, durations, col, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
